{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f54e71d-dde3-41ab-9c04-b464dc3c308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo code : 가짜(거짓)의 코드 \n",
    "# 만약 내가 yest24에서 크롤링 한다면?\n",
    "# 1) 수집하고자하는 사이트의 주소를 확인한다. 그리고 크롤러하기 위해 변수화하고, 크롤링한다. \n",
    "# 2) 해당 사이트에서 F12 > [Network] > 페이지 새로고침 > 첫번째 항목 클릭, User-Agent 로 신원을 확인해준다.\n",
    "# 3) BeautifulSoup : 보다 깔끔하게 정렬\n",
    "# 4) 해당 사이트에서 책 제목과 저자의 태그를 확인한다. \n",
    "# 5) 책 제목과 저자의 정보를 크롤러를 통해서 찾아온다. \n",
    "# 6) 크롤러가 찾아온 정보를 변수 생성 후 저장한다. title_tag, author_tag\n",
    "# 7) 해당 변수를 출력한다. print(title_tag.text)\n",
    "# 텍스트만 보고 싶을 때 .text\n",
    "# divide & conquer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75f563f-4b26-42df-9e3b-ad7b64c4577c",
   "metadata": {},
   "source": [
    "- 200 : 클라이언트 요청에 서버가 문제 없이 통신했다\n",
    "- 300 : 클라이언트 요청에 서버가 통신했으나 다른 곳으로 우회시켰다\n",
    "- 400 : 클라이언트 요청이 잘못되어 서버에서 정상적으로 응답 불가\n",
    "- 500 : 클라이언트 요청은 문제가 없으나 서버에서 정상적으로 응답 불가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9394f1a3-95d8-486d-a08d-516ac2f9c670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 부의 추월차선 (10주년 스페셜 에디션), - 엠제이 드마코 저/신소영 역\n",
      "2, 달러는 왜 비트코인을 싫어하는가, - 사이페딘 아모스 저/위대선 역\n",
      "3, 경제기사 궁금증 300문 300답, - 곽해선 저\n",
      "4, 트럼프 2.0 시대, - 박종훈 저\n",
      "5, 시대예보: 호명사회, - 송길영 저\n",
      "6, 넛지: 파이널 에디션, - 리처드 탈러, 캐스 선스타인 저/이경식 역/최정규 감수\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.yes24.com/product/category/steadyseller?pageNumber=1&pageSize=24&categoryNumber=001001025007\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36\"\n",
    "} #딕셔너리 = 사전 = 뜻\n",
    "\n",
    "response = requests.get(url, headers)\n",
    "response.encoding = \"utf-8\" # utf = 유니코드. 웹 사용 국가를 파악 -> 언어, 이모지 포함해서 출력. \n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "books = soup.select(\"div.item_info\")\n",
    "\n",
    "# for book in books[5:11] : # [5:11] 5번에서 11번까지 값만 가져오기\n",
    "#     title_tag = book.select_one(\"a.gd_name\")\n",
    "#     author_tag = book.select_one(\"span.authPub.info_auth\")\n",
    "#     print(title_tag.text.strip(), author_tag.text.strip())\n",
    "\n",
    "for i, book in enumerate(books[5:11], 1) :\n",
    "    title_tag = book.select_one(\"a.gd_name\")\n",
    "    author_tag = book.select_one(\"span.authPub.info_auth\")\n",
    "    print(f\"{i}, {title_tag.text.strip()}, - {author_tag.text.strip()}\")\n",
    "\n",
    "    \n",
    "# print(dir(books))\n",
    "# title_tag = soup.select(\"a.gd_name\") # selcet만 하면 all, select_one하면 최초의 값 하나\n",
    "# author_tag = soup.select_one(\"span.authPub.info_auth\")\n",
    "\n",
    "# print(title_tag.text) #문자열에서만 사용 가능\n",
    "# print(type(title_tag))\n",
    "# print(dir(title_tag)) 속성 파악 함수 dir. 그 중 'iter' 반복문.\n",
    "\n",
    "# for title in title_tag : \n",
    "#     print(title.text)\n",
    "\n",
    "# # for author in author_tag :\n",
    "#     print(author.text.strip()) # strip : 행 바꿈 사라짐. 엔터를 치는 순간 컴퓨터는 \\n 입력(escape sequnce) n->일반적인 스펠링 문자, 개행 처리 = 행 바꿈"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
