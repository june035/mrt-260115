{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0daa49-c245-4d9b-a452-d12c8fded1fc",
   "metadata": {},
   "source": [
    "# 파이썬 프로그래밍 언어를 통해서 데이터 수집.분석 활용 마케터가 기대하는 것\n",
    "1) 원하는 데이터를 수집 : 웹사이트에 들어가서 크롤링\n",
    "2) 수집해온 데이터를 저장 : 엑셀, csv, xml, json\n",
    "3) 저장한 데이터를 분석 : MySQL\n",
    "4) 데이터 전처리 : 타입(정수, 빈값, 문자 등) 동일화\n",
    "5) 데이터 시각화 : plotly, pandas\n",
    "6) 데이터 예측 : Numpy, pytorch\n",
    "\n",
    "> 위 데이터 수집.분석.예측 과정 가운데 마케팅적 사고 관점으로 문제 해결 능력을 추가해서 효과적인 인사이트 도출\n",
    "\n",
    "\n",
    "- 크롤링: 웹사이트에서 내가 원하는 부분을 자동으로 추출해오는 기능\n",
    "1) 정적인 웹사이트 구현(html, css, js) : requests\n",
    "2) spa(single page app) 방식으로 구현(react.js, vue.js, angluar.js) : selenium\n",
    "3) 여러 절차를 거쳐서 방대한 데이터를 가져와야하는 경우 : scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426fc5f2-6cd9-468d-b9b8-f6bdc60e0be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 모듈이 없을 경우\n",
    "# !pip install 라이브러리모듈이름 (package in python)\n",
    "# pip install 은 원래 터미널 전용 명령어. ! 로 주피터노트북에서 가능하게 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a16829b-ece0-45e7-9489-b6fe7f353a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"키오스크 어려우면 직원 부르세요!\" 디지털 취약계층 접근성 높인다 서울 시내 한 영화관에서 한 시민이 키오스크를 이용하는 모습. 뉴스1 [파이낸셜뉴스] 디지털 취약 계층도 차별 없이 인공지능(AI)과 디지털 기술 혜택을 누릴 수 있게 하기 위한 디지털포용법이 오는 22일부터 시행된다. 국가·지방차지단체·공공기관이 무인정보단말기(키오스크), 태블릿 등 제품이나 정보 서비스를 새롭게 도입할 때 디지털 취약 파이낸셜뉴스 방금 전 - https://v.daum.net/v/20260121164504803\n",
      "이재명 \"용인 반도체 뒤집기 어렵다\"…이전 논쟁에 쐐기 아이뉴스24 3분 전 - https://v.daum.net/v/20260121164304686\n",
      "[현장] 박윤규 NIPA 원장 \"공공기관 AX, 국가대표 AI 활용 긍정 검토\" 지디넷코리아 7분 전 - https://v.daum.net/v/20260121163824453\n",
      "[단독] 국정자원 화재 교훈 잊었나...민관 '오프라인 백업' 포기 전자신문 13분 전 - https://v.daum.net/v/20260121163247164\n",
      "이민단속국에 뿔난 테크기업 임직원 \"CEO들, 백악관에 철수 요구하라\" 연합뉴스TV 16분 전 - https://v.daum.net/v/20260121162943010\n",
      "임종인 고려대 교수 \"ISMS-P 개편, 체크리스트 수준 안돼\" 지디넷코리아 16분 전 - https://v.daum.net/v/20260121162923981\n",
      "이해진, 네이버 '국대 AI' 탈락 후 첫 행보는 한은…\"더 열심히 해야죠\" 이데일리 21분 전 - https://v.daum.net/v/20260121162447742\n",
      "크래프톤, 산하 스튜디오 19개로 확대…\"프랜차이즈 IP 확보 추진\" 데일리안 23분 전 - https://v.daum.net/v/20260121162215613\n",
      "[체험기] 행성 개척의 낭만을 담다. SF 오픈월드로 돌아온 명일방주 엔드필드 게임동아 25분 전 - https://v.daum.net/v/20260121162105573\n"
     ]
    }
   ],
   "source": [
    "import requests #requests : 데이터를 수집해오는 크롤러\n",
    "import bs4 #찾아온 데이터를 보다 쉽게 이해하고 해석할 수 있도록 아름답게 바꿔주는 역할\n",
    "\n",
    "url = \"https://news.daum.net/tech\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers) \n",
    "#get은 메서드 함수 = 독립함수 아니고, requests에 대한 함수\n",
    "response.encoding = \"utf-8\"\n",
    "soup = bs4.BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "articles = soup.select(\"ul.list_newsheadline2 li a.item_newsheadline2\")\n",
    "\n",
    "for article in articles :\n",
    "    title = article.text.strip()\n",
    "    link = article[\"href\"]\n",
    "    print(f\"{title} - {link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4401e32-dec9-472e-af25-34a77a0b77a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마케팅(영어: marketing)은 시장 경제(영어: exchange relationship) 또는 수요를 관리하는 경영학의 한 분야이다. 소비자를 대상으로 고객을 창조하고 유지 · 관리함으로써 고정고객으로 만드는 모든 활동 즉, 고객과 관련된 모든 활동을 의미한다. 마케팅은 광고, 영업 등을 포함하며 창의성을 내포하는 산업이자 소비자가 가질 수 있는 미래의 요구와 욕구를 예측하는 일로 한정되었으나 21세기 이후에는 어떤 '잠재적인 욕구'를 자극하여 표면상으로 이끌어 내는 행위나 동기로 용어의 적용 범위가 확대되고, 시장에서 벗어나 일상의 행위에서도 마케팅이라는 용어가 등장하게 되었다.\n",
      "마케팅은 판매행위를 어떻게 구성하고 전달할 것인지에 대한 모든 일련의 행위를 포함하며, 또한 상대방이 자신에 대해 가지고 있는 잠재욕구를 자극하여 필요로 하게끔 만드는 행위와, 상품과 용역을 생산자로부터 소비자에게 원활히 이전하기 위한 비즈니스 활동을 포함한다. 즉, 생산자와 소비자의 희망을 결합해서 능률적인 공급을 하는 것이 마케팅이다. 그것을 위한 활동으로 시장조사, 상품화 계획, 판매촉진, 선전 · 광고, 디지털 마케팅(digital marketing) 등이 있다.\n"
     ]
    }
   ],
   "source": [
    "# 위키피디아 사이트 > 마케팅을 검색 후 결과 값의 첫 문단 크롤링\n",
    "\n",
    "import requests\n",
    "import bs4 \n",
    "\n",
    "url = \"https://ko.wikipedia.org/wiki/%EB%A7%88%EC%BC%80%ED%8C%85\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers) \n",
    "response.encoding = \"utf-8\"\n",
    "soup = bs4.BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "paragraph = soup.select(\"div.mw-content-ltr.mw-parser-output > p\")\n",
    "\n",
    "for p in paragraph[0:2] :\n",
    "    print(p.get_text().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b2f8be-890a-4cf1-9049-886a91cd2938",
   "metadata": {},
   "source": [
    "# .text : 속성 VS get_text() : 메서드 함수\n",
    "# 둘 다 클래스에서 비롯된 값\n",
    "# .text = 찾아오려고 하는 텍스트를 여과없이 찾아온다\n",
    "# .text는 속성이므로 옵션(인자값)을 넣을 수 없다. strip() 을 넣어야 한다\n",
    "# get_text() 는 strip을 옵션으로 넣을 수 있다\n",
    "# print(p.get_text().strip()) = print(p.get_text(\" \", strip=True))\n",
    "\n",
    "\"\"\"\n",
    "<p>안녕<br><sapn>반가워요</span></p>\n",
    "\n",
    "> p.text 한다면\n",
    "안녕\n",
    "반가워요\n",
    "\n",
    "> p.get_text(\" \") 별도의 값을 넣어줄 수 있다\n",
    "p.get_text(\" \", strip=True) 공백 없애는 옵션\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "babd1d09-7ee7-41b3-a416-f80e80c9e2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "□  (종합) 당분간 전국 강추위, 오늘부터 내일 오전 사이 전라서해안과 제주도 중심 많은 눈, 빙판길과 도로 살얼음 주의○  (오늘, 21일) 전국 대부분 대체로 맑겠으나, 충청권과 전라권, 제주도 대체로 흐림,\n",
      "                        충남권과 충북중.남부, 전라서해안, 전북남부내륙, 광주.전남중부내륙.서부남해안, 제주도 곳에 따라 눈,\n",
      "                        밤(18~24시)에 경기남부서해안과 그 밖의 전라권 곳에 따라 0.1cm 미만 눈 날림○  (내일, 22일) 전국 대체로 맑겠으나, 충남권과 전라권, 제주도 대체로 흐림,\n",
      "                       전라서해안과 전북남부내륙, 광주.전남중부내륙.서부남해안, 제주도 곳에 따라 눈,\n",
      "                       새벽(00~06시)까지 충남권과 충북중.남부, 늦은 밤(21~24시)에 충남서해안 곳에 따라 눈,\n",
      "                       새벽(00~06시)에 경기남부서해안, 오전(06~12시)에 충남권과 충북중.남부 곳에 따라 0.1cm 미만 눈 날림○  (모레, 23일) 충남권과 전라권, 제주도 대체로 흐리고, 그 밖의 전국 가끔 구름많음,\n",
      "                       새벽(00~06시)부터 오전(06~12시) 사이 충남서해안과 광주.전남중부내륙, 전라서해안 곳에 따라 눈,\n",
      "                       제주도는 새벽(00~06시)에, 오후(12~18시)부터 저녁(18~21시) 사이 곳에 따라 비 또는 눈, \n",
      "                       늦은 밤(21~24시)부터 충남서해안 곳에 따라 눈○  (글피, 24일) 전국 대부분 대체로 맑겠으나, 제주도 구름많겠고, 충남권과 전라권 대체로 흐리겠음,\n",
      "                       새벽(00~06시)부터 오전(06~12시) 사이 충남서해안과 전라서해안 곳에 따라 눈○  (그글피, 25일) 전국 대부분 대체로 맑다가 늦은 오후부터 구름많아지겠으나, 전라권과 제주도 가끔 구름많음\n",
      "*  예상 적설(21~22일)-  (수도권) 서해5도: 1cm 안팎-  (충청권) 세종.충남북부내륙: 1~5cm/ 충북중.남부: 1~3cm / 대전.충남(북부내륙 제외): 1cm 안팎  -  (전라권) 전북서해안, 전남서해안: 2~7cm(많은 곳 10cm 이상)/ 광주.전남중부내륙.서부남해안, 전북남부내륙: 1~5cm-  (경상권) 울릉도.독도: 5~20cm-  (제주도) 제주도산지: 5~15cm(많은 곳 20cm 이상)/ 제주도중산간: 5~10cm/ 제주도해안: 2~7cm\n",
      "*  예상 강수량(21~22일)-  (수도권) 서해5도: 1mm 미만-  (충청권) 세종.충남북부내륙, 충북중.남부: 5mm 미만/ 대전.충남(북부내륙 제외): 1mm 안팎-  (전라권) 전북서해안, 전남서해안: 5mm 안팎/ 광주.전남중부내륙.서부남해안, 전북남부내륙: 5mm 미만-  (경상권) 울릉도.독도: 5~20mm-  (제주도) 제주도: 5~15mm\n",
      "*  예상 적설(23일) -  (수도권, 23일 새벽~오후) 서해5도: 1~3cm-  (충청권, 23일) 충남서해안: 1~3cm-  (전라권, 23일 새벽~오전) 광주.전남중부내륙.서해안, 전북서해안: 1~3cm-  (제주도, 23일 새벽~저녁) 제주도산지.중산간: 1~3cm, 제주도해안: 1cm 안팎\n",
      "*  예상 강수량(23일) -  (수도권, 23일 새벽~오후) 서해5도: 1mm 안팎-  (충청권, 23일) 충남서해안: 1mm 안팎-  (전라권, 23일 새벽~오전) 광주.전남중부내륙.서해안, 전북서해안: 1mm 안팎-  (제주도, 23일 새벽~저녁) 제주도: 1mm 안팎\n"
     ]
    }
   ],
   "source": [
    "# 기상청 홈페이지에 가서 \n",
    "\n",
    "import requests\n",
    "import bs4 \n",
    "\n",
    "url = \"https://www.weather.go.kr/w/forecast/overall/short-term.do#dong/1165053100/37.499782/127.028584/%EC%84%9C%EC%9A%B8%ED%8A%B9%EB%B3%84%EC%8B%9C%20%EC%84%9C%EC%B4%88%EA%B5%AC%20%EC%84%9C%EC%B4%884%EB%8F%99/LOC/%EC%9C%84%EA%B2%BD%EB%8F%84(37.50,127.03)\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers) \n",
    "response.encoding = \"utf-8\"\n",
    "soup = bs4.BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "results = soup.select(\"div.cmp-view-content\")\n",
    "\n",
    "for r in results :\n",
    "    print(r.get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0614950-d537-4cf9-a725-7901ea5a3b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'□  (종합) 당분간 전국 강추위, 오늘부터 내일 오전 사이 전라서해안과 제주도 중심 많은 눈, 빙판길과 도로 살얼음 주의 ○  (오늘, 21일) 전국 대부분 대체로 맑겠으나, 충청권과 전라권, 제주도 대체로 흐림, 충남권과 충북중.남부, 전라서해안, 전북남부내륙, 광주.전남중부내륙.서부남해안, 제주도 곳에 따라 눈, 밤(18~24시)에 경기남부서해안과 그 밖의 전라권 곳에 따라 0.1cm 미만 눈 날림 ○  (내일, 22일) 전국 대체로 맑겠으나, 충남권과 전라권, 제주도 대체로 흐림, 전라서해안과 전북남부내륙, 광주.전남중부내륙.서부남해안, 제주도 곳에 따라 눈, 새벽(00~06시)까지 충남권과 충북중.남부, 늦은 밤(21~24시)에 충남서해안 곳에 따라 눈, 새벽(00~06시)에 경기남부서해안, 오전(06~12시)에 충남권과 충북중.남부 곳에 따라 0.1cm 미만 눈 날림 ○  (모레, 23일) 충남권과 전라권, 제주도 대체로 흐리고, 그 밖의 전국 가끔 구름많음, 새벽(00~06시)부터 오전(06~12시) 사이 충남서해안과 광주.전남중부내륙, 전라서해안 곳에 따라 눈, 제주도는 새벽(00~06시)에, 오후(12~18시)부터 저녁(18~21시) 사이 곳에 따라 비 또는 눈, 늦은 밤(21~24시)부터 충남서해안 곳에 따라 눈 ○  (글피, 24일) 전국 대부분 대체로 맑겠으나, 제주도 구름많겠고, 충남권과 전라권 대체로 흐리겠음, 새벽(00~06시)부터 오전(06~12시) 사이 충남서해안과 전라서해안 곳에 따라 눈 ○  (그글피, 25일) 전국 대부분 대체로 맑다가 늦은 오후부터 구름많아지겠으나, 전라권과 제주도 가끔 구름많음 *  예상 적설(21~22일) -  (수도권) 서해5도: 1cm 안팎 -  (충청권) 세종.충남북부내륙: 1~5cm/ 충북중.남부: 1~3cm / 대전.충남(북부내륙 제외): 1cm 안팎 -  (전라권) 전북서해안, 전남서해안: 2~7cm(많은 곳 10cm 이상)/ 광주.전남중부내륙.서부남해안, 전북남부내륙: 1~5cm -  (경상권) 울릉도.독도: 5~20cm -  (제주도) 제주도산지: 5~15cm(많은 곳 20cm 이상)/ 제주도중산간: 5~10cm/ 제주도해안: 2~7cm *  예상 강수량(21~22일) -  (수도권) 서해5도: 1mm 미만 -  (충청권) 세종.충남북부내륙, 충북중.남부: 5mm 미만/ 대전.충남(북부내륙 제외): 1mm 안팎 -  (전라권) 전북서해안, 전남서해안: 5mm 안팎/ 광주.전남중부내륙.서부남해안, 전북남부내륙: 5mm 미만 -  (경상권) 울릉도.독도: 5~20mm -  (제주도) 제주도: 5~15mm *  예상 적설(23일) -  (수도권, 23일 새벽~오후) 서해5도: 1~3cm -  (충청권, 23일) 충남서해안: 1~3cm -  (전라권, 23일 새벽~오전) 광주.전남중부내륙.서해안, 전북서해안: 1~3cm -  (제주도, 23일 새벽~저녁) 제주도산지.중산간: 1~3cm, 제주도해안: 1cm 안팎 *  예상 강수량(23일) -  (수도권, 23일 새벽~오후) 서해5도: 1mm 안팎 -  (충청권, 23일) 충남서해안: 1mm 안팎 -  (전라권, 23일 새벽~오전) 광주.전남중부내륙.서해안, 전북서해안: 1mm 안팎 -  (제주도, 23일 새벽~저녁) 제주도: 1mm 안팎'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import bs4 \n",
    "\n",
    "url = \"https://www.weather.go.kr/w/forecast/overall/short-term.do#dong/1165053100/37.499782/127.028584/%EC%84%9C%EC%9A%B8%ED%8A%B9%EB%B3%84%EC%8B%9C%20%EC%84%9C%EC%B4%88%EA%B5%AC%20%EC%84%9C%EC%B4%884%EB%8F%99/LOC/%EC%9C%84%EA%B2%BD%EB%8F%84(37.50,127.03)\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers) \n",
    "response.encoding = \"utf-8\"\n",
    "soup = bs4.BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "results = soup.select_one(\"p.summary\") #클래스(summary)가 여러 개일 수 있다, 그럴 땐 상위 클래스를 가져와야 한다.\n",
    "clean_text = results.get_text(\" \", strip=True)\n",
    "\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e5056b6-18e6-4577-a4f7-668ae6982f7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SelectorSyntaxError",
     "evalue": "Malformed class selector at position 32\n  line 1:\ndiv.styles_mb_space2__dk46ts4t a. \n                                ^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSelectorSyntaxError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m response\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m soup \u001b[38;5;241m=\u001b[39m bs4\u001b[38;5;241m.\u001b[39mBeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m jobs \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv.styles_mb_space2__dk46ts4t a. \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m jobskorea \u001b[38;5;129;01min\u001b[39;00m jobs :\n\u001b[0;32m     18\u001b[0m     title \u001b[38;5;241m=\u001b[39m jobkorea\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\bs4\\element.py:2116\u001b[0m, in \u001b[0;36mTag.select\u001b[1;34m(self, selector, namespaces, limit, **kwargs)\u001b[0m\n\u001b[0;32m   2096\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, selector, namespaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform a CSS selection operation on the current element.\u001b[39;00m\n\u001b[0;32m   2098\u001b[0m \n\u001b[0;32m   2099\u001b[0m \u001b[38;5;124;03m    This uses the SoupSieve library.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2114\u001b[0m \u001b[38;5;124;03m    :rtype: bs4.element.ResultSet\u001b[39;00m\n\u001b[0;32m   2115\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcss\u001b[38;5;241m.\u001b[39mselect(selector, namespaces, limit, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\bs4\\css.py:162\u001b[0m, in \u001b[0;36mCSS.select\u001b[1;34m(self, select, namespaces, limit, flags, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rs(\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mselect(\n\u001b[0;32m    163\u001b[0m         select, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtag, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ns(namespaces, select), limit, flags,\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    165\u001b[0m     )\n\u001b[0;32m    166\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\soupsieve\\__init__.py:147\u001b[0m, in \u001b[0;36mselect\u001b[1;34m(select, tag, namespaces, limit, flags, custom, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mselect\u001b[39m(\n\u001b[0;32m    136\u001b[0m     select: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    137\u001b[0m     tag: bs4\u001b[38;5;241m.\u001b[39mTag,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    144\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[bs4\u001b[38;5;241m.\u001b[39mTag]:\n\u001b[0;32m    145\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Select the specified tags.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcompile\u001b[39m(select, namespaces, flags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mselect(tag, limit)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\soupsieve\\__init__.py:65\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(pattern, namespaces, flags, custom, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot process \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument on a compiled selector list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pattern\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cp\u001b[38;5;241m.\u001b[39m_cached_css_compile(\n\u001b[0;32m     66\u001b[0m     pattern,\n\u001b[0;32m     67\u001b[0m     ct\u001b[38;5;241m.\u001b[39mNamespaces(namespaces) \u001b[38;5;28;01mif\u001b[39;00m namespaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m namespaces,\n\u001b[0;32m     68\u001b[0m     ct\u001b[38;5;241m.\u001b[39mCustomSelectors(custom) \u001b[38;5;28;01mif\u001b[39;00m custom \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m custom,\n\u001b[0;32m     69\u001b[0m     flags\n\u001b[0;32m     70\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\soupsieve\\css_parser.py:208\u001b[0m, in \u001b[0;36m_cached_css_compile\u001b[1;34m(pattern, namespaces, custom, flags)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Cached CSS compile.\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m custom_selectors \u001b[38;5;241m=\u001b[39m process_custom(custom)\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cm\u001b[38;5;241m.\u001b[39mSoupSieve(\n\u001b[0;32m    203\u001b[0m     pattern,\n\u001b[0;32m    204\u001b[0m     CSSParser(\n\u001b[0;32m    205\u001b[0m         pattern,\n\u001b[0;32m    206\u001b[0m         custom\u001b[38;5;241m=\u001b[39mcustom_selectors,\n\u001b[0;32m    207\u001b[0m         flags\u001b[38;5;241m=\u001b[39mflags\n\u001b[1;32m--> 208\u001b[0m     )\u001b[38;5;241m.\u001b[39mprocess_selectors(),\n\u001b[0;32m    209\u001b[0m     namespaces,\n\u001b[0;32m    210\u001b[0m     custom,\n\u001b[0;32m    211\u001b[0m     flags\n\u001b[0;32m    212\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\soupsieve\\css_parser.py:1129\u001b[0m, in \u001b[0;36mCSSParser.process_selectors\u001b[1;34m(self, index, flags)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess_selectors\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ct\u001b[38;5;241m.\u001b[39mSelectorList:\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Process selectors.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_selectors(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselector_iter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpattern), index, flags)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\soupsieve\\css_parser.py:965\u001b[0m, in \u001b[0;36mCSSParser.parse_selectors\u001b[1;34m(self, iselector, index, flags)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    964\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 965\u001b[0m         key, m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iselector)\n\u001b[0;32m    967\u001b[0m         \u001b[38;5;66;03m# Handle parts\u001b[39;00m\n\u001b[0;32m    968\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat_rule\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\soupsieve\\css_parser.py:1122\u001b[0m, in \u001b[0;36mCSSParser.selector_iter\u001b[1;34m(self, pattern)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1121\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid character \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m position \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1122\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SelectorSyntaxError(msg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpattern, index)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m## END PARSING\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mSelectorSyntaxError\u001b[0m: Malformed class selector at position 32\n  line 1:\ndiv.styles_mb_space2__dk46ts4t a. \n                                ^"
     ]
    }
   ],
   "source": [
    "# 잡코리아 > 컨텐츠마케터 직무 공고 타이틀+링크까지해서 10개만 수집하기\n",
    "\n",
    "import requests\n",
    "import bs4 \n",
    "\n",
    "url = \"https://www.jobkorea.co.kr/Search/?stext=%EC%BB%A8%ED%85%90%EC%B8%A0%EB%A7%88%EC%BC%80%ED%84%B0\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers) \n",
    "response.encoding = \"utf-8\"\n",
    "soup = bs4.BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "jobs = soup.select(\"div.styles_mb_space2__dk46ts4t a. \")\n",
    "\n",
    "for jobskorea in jobs :\n",
    "    title = jobkorea.text.strip()\n",
    "    link = jobkorea[\"href\"]\n",
    "    print(f\"{title} - {link}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
